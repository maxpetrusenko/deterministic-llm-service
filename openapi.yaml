openapi: 3.0.3
info:
  title: Deterministic LLM Gateway
  description: |
    Production-grade HTTP gateway for LLM providers (OpenAI, Anthropic) with
    reliability controls: retries, circuit breakers, rate limiting, idempotency,
    structured logging, and schema validation.

    **Features:**
    - ‚ö° Exponential backoff retries
    - üîå Circuit breakers (Opossum)
    - üö¶ Rate limiting per IP
    - üîë Idempotency key support
    - üìä Pino structured logging
    - ‚úÖ Zod schema validation
    - üõ°Ô∏è Configurable timeouts
  version: 0.1.0
  contact:
    name: maxpetrusenko
    url: https://github.com/maxpetrusenko/deterministic-llm-service
  license:
    name: MIT

servers:
  - url: http://localhost:3000
    description: Local development server
  - url: https://your-production-gateway.com
    description: Production server

tags:
  - name: health
    description: Health check endpoints
  - name: chat
    description: Chat completion endpoints

paths:
  /health:
    get:
      tags: [health]
      summary: Health check
      description: Returns the health status of the gateway
      operationId: healthCheck
      responses:
        '200':
          description: Gateway is healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HealthResponse'
              example:
                status: healthy
                timestamp: '2025-02-18T19:00:00.000Z'
                uptime: 1234.567
                requestId: '550e8400-e29b-41d4-a716-446655440000'

  /v1/chat/completions:
    post:
      tags: [chat]
      summary: Create chat completion
      description: |
        Creates a model response for the given chat conversation.
        Supports both OpenAI and Anthropic providers via unified interface.
      operationId: createChatCompletion
      parameters:
        - name: X-Request-Id
          in: header
          description: Unique request identifier for tracing. Auto-generated if not provided.
          schema:
            type: string
            format: uuid
          example: '550e8400-e29b-41d4-a716-446655440000'
        - name: X-Idempotency-Key
          in: header
          description: |
            Key to prevent duplicate processing. Responses are cached for 1 hour.
            If the same key is sent again, the cached response is returned.
          schema:
            type: string
          example: 'my-request-123'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              simple:
                summary: Simple user message
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: user
                      content: Hello, how are you?
              withSystem:
                summary: With system prompt
                value:
                  model: gpt-4o-mini
                  messages:
                    - role: system
                      content: You are a helpful assistant.
                    - role: user
                      content: Explain quantum computing.
              anthropic:
                summary: Anthropic provider
                value:
                  model: claude-3-haiku-20240307
                  provider: anthropic
                  messages:
                    - role: user
                      content: What is the capital of France?
      responses:
        '200':
          description: Successful completion
          headers:
            X-Request-Id:
              description: Request identifier
              schema:
                type: string
            X-Cached:
              description: 'true if response was served from idempotency cache'
              schema:
                type: boolean
            X-RateLimit-Limit:
              description: Requests per rate limit window
              schema:
                type: integer
            X-RateLimit-Remaining:
              description: Remaining requests in current window
              schema:
                type: integer
            X-RateLimit-Reset:
              description: ISO timestamp when rate limit resets
              schema:
                type: string
                format: date-time
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
              example:
                id: 'chatcmpl-123'
                content: 'Hello! I am doing well, thank you for asking.'
                model: gpt-4o-mini
                finishReason: stop
                usage:
                  promptTokens: 10
                  completionTokens: 9
                  totalTokens: 19
        '400':
          description: Invalid request (validation error)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              example:
                error: Validation error
                details:
                  - code: invalid_type
                    expected: string
                    received: undefined
                    path: [model]
                    message: Required
        '429':
          description: Rate limit exceeded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RateLimitError'
              example:
                error: Too many requests
                retryAfter: 45
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
              example:
                error: Internal server error
                requestId: '550e8400-e29b-41d4-a716-446655440000'

components:
  schemas:
    Message:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant]
          description: The role of the message author
        content:
          type: string
          description: The content of the message

    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: |
            Model identifier (e.g., 'gpt-4o-mini', 'claude-3-haiku-20240307').
            The model must be supported by the selected provider.
          example: gpt-4o-mini
        messages:
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/Message'
          description: Array of messages in the conversation
        temperature:
          type: number
          minimum: 0
          maximum: 2
          description: Sampling temperature (0 = deterministic, 2 = very random)
          example: 0.7
        maxTokens:
          type: number
          minimum: 1
          description: Maximum tokens to generate in the completion
          example: 1000
        provider:
          type: string
          enum: [openai, anthropic]
          description: |
            LLM provider to use. Defaults to 'openai' or DEFAULT_PROVIDER env var.
          example: openai
        timeout:
          type: number
          minimum: 1
          default: 30000
          description: Request timeout in milliseconds
          example: 30000

    ChatCompletionResponse:
      type: object
      required:
        - id
        - content
        - model
        - finishReason
        - usage
      properties:
        id:
          type: string
          description: Unique completion identifier
        content:
          type: string
          description: The generated message content
        model:
          type: string
          description: The model used for the completion
        finishReason:
          type: string
          enum: [stop, length, content_filter]
          description: Reason the completion finished
        usage:
          type: object
          required:
            - promptTokens
            - completionTokens
            - totalTokens
          properties:
            promptTokens:
              type: integer
              description: Tokens in the prompt
            completionTokens:
              type: integer
              description: Tokens in the completion
            totalTokens:
              type: integer
              description: Total tokens used

    HealthResponse:
      type: object
      required:
        - status
        - timestamp
        - uptime
        - requestId
      properties:
        status:
          type: string
          enum: [healthy]
          description: Health status
        timestamp:
          type: string
          format: date-time
          description: Current server time
        uptime:
          type: number
          format: float
          description: Server uptime in seconds
        requestId:
          type: string
          format: uuid
          description: Request identifier

    ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          type: string
          description: Error message
        requestId:
          type: string
          format: uuid
          description: Request identifier for debugging
        details:
          type: array
          description: Detailed validation errors (for Zod validation failures)
          items:
            type: object

    RateLimitError:
      type: object
      required:
        - error
        - retryAfter
      properties:
        error:
          type: string
          example: Too many requests
        retryAfter:
          type: integer
          description: Seconds until rate limit resets

  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      description: |
        API authentication (not yet implemented - placeholder for future)
        Current implementation uses environment variables for provider keys.
